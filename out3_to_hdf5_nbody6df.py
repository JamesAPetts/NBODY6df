#!/usr/bin/python

# Code to convert NBODY6df OUT3 file to HDF5 file format
import numpy as np
import struct
import h5py
import sys
import os
import argparse

def read_nbody6(f5, file, sev): 
    """Read in the nbody6 output file(s).
    
       Keyword arguments:
       filename -- the OUT3 file generated by nbody6
    
    """
    # open NBODY6 file
    f = open(file,'r')

    # start looping over time and reading the nbody6 data. 
    # itime tracks the number of timesteps outputted.
    itime = -1
    
    # runs on some computers seem to generate extra bytes after the record length.
    # 'extra' and its associated reads below take care of that.
    extra = 0 
    
    byte = f.read(4) # begin header block
    model = 0

    while byte != "":
        blocksize1 = struct.unpack('i',byte)[0] # header block size
        if extra == 1:
            f.read(4)
        itime = itime + 1
        # read the header for this time
        ntot = struct.unpack('i',f.read(4))[0] #ntot
        if ntot < 10 and itime == 0:
            # check for a nonsensical ntot value, 
            # which is symptomatic of bizarre extra record padding that occurs on some
            # systems. if needed, include extra reads to deal with these.
            extra = 1
            ntot = struct.unpack('i',f.read(4))[0]
            print 'extra! '+str(extra)
            
        model = struct.unpack('i',f.read(4))[0] #model
        nrun =  struct.unpack('i',f.read(4))[0] #nrun
        nk = struct.unpack('i',f.read(4))[0]    #nk

        blocksize2 = struct.unpack('i',f.read(4))[0] #end header block size
        if extra == 1:
            f.read(4)
            
        # check for consistency
        if blocksize1 != blocksize2:
            print 'header trouble! t = '+str(itime)+' '+str(blocksize1)+' '+str(blocksize2)
            sys.exit(1)
                
        # now read the star data
        blocksize1 = struct.unpack('i',f.read(4))[0] #begin data block size
        if extra == 1:
            f.read(4)
                        
        alist = []
        for i in range(nk):
            alist.append(struct.unpack('f',f.read(4))[0]) #Sverre's 'as'
        alist.append(ntot)

        stardata = np.zeros((ntot, 12))
        datalist=[] # masses
        for i in range(ntot):
            datalist.append(struct.unpack('f',f.read(4))[0])

        stardata[:,0] = datalist
         
        datalistx=[] # positions
        datalisty=[]
        datalistz=[]
        for i in range(ntot):           
            datalistx.append(struct.unpack('f',f.read(4))[0])
            datalisty.append(struct.unpack('f',f.read(4))[0])
            datalistz.append(struct.unpack('f',f.read(4))[0]) 

        stardata[:,1] = datalistx
        stardata[:,2] = datalisty
        stardata[:,3] = datalistz
        
        datalistx=[] # velocities
        datalisty=[]
        datalistz=[]

        for i in range(ntot):           
            datalistx.append(struct.unpack('f',f.read(4))[0])
            datalisty.append(struct.unpack('f',f.read(4))[0])
            datalistz.append(struct.unpack('f',f.read(4))[0])

        stardata[:,4] = datalistx
        stardata[:,5] = datalisty
        stardata[:,6] = datalistz    
            
        datalist=[] # names
        for i in range(ntot):
            datalist.append(struct.unpack('i',f.read(4))[0])
        stardata[:,7] = datalist

        datalist=[] # bound
        for i in range(ntot):           
            datalist.append(struct.unpack('i',f.read(4))[0])
        stardata[:,8] = datalist
        

        if (sev):
            datalist=[] # kstar
            for i in range(ntot):
                datalist.append(struct.unpack('i',f.read(4))[0])
            stardata[:,9] = datalist
            

            datalist=[] # lum
            for i in range(ntot):
                datalist.append(struct.unpack('f',f.read(4))[0])
            stardata[:,10] = datalist
            

            datalist=[] # teff
            for i in range(ntot):
                datalist.append(struct.unpack('f',f.read(4))[0])
            stardata[:,11] = datalist
            
 
        blocksize2 = struct.unpack('i',f.read(4))[0] #end data block size
        if extra == 1:
            f.read(4)

        # check for consistency
        if blocksize1 != blocksize2:
            print 'star data trouble! '+str(itime)
            sys.exit(3)

        if itime >= 2380:
            break
                
        splitarray = np.hsplit(stardata, [1,4,7,8,9,10,11])

        # Output snapshot in hdf5 file
        h5output(f5, alist, splitarray, model-1, sev) 
        
        # next header blocksize for loop control
        byte = f.read(4) # begin header block
                          
    # close OUT3 and other files if present
    f.close()


def h5output(f5, alist, splitarray, model, sev):
    """output the nbody6 snapshot data in hdf5 format. Plots the first snapshot
       just to make sure it's sensible looking.
    
       Keyword arguments:
       outputfilename -- the name of the hdf5 file to create
       alist -- header data from the nbody6 data. this is sverre's AS list.
       splitarray -- the data that has been parsed from the nbody6 files
    """

    # Create model group
    modgrp = f5.create_group("%05d"%model)
    f5.attrs["nmod"]=model+1        # Number of models, updated everytime a snapshot is written

    # create groups for the "stars" and "cluster" data 
    stargrp    = f5.create_group("%05d/stars"%model)
    clustergrp = f5.create_group("%05d/cluster"%model)

    
    # Assume the following for AS list:
    # AS(0) = TTOT
    # AS(1) = NBIN
    # AS(2) = RBAR 
    # AS(3) = ZMBAR
    # AS(4) = TSTAR
    # AS(5) = VSTAR
    # AS(6:8) = RDENS
    # AS(9:11) = RG
    # AS(12:14) = VG
    # AS(15) = RC
    # AS(16) = NC
    # AS(17) = VC
    # AS(18) = MC
    # AS(19) = RHOM
    #  Jpetts - added AS variables bellow.
    # AS(20) = COULOG
    # AS(21) = NBOUND   (in roche volume)
    # AS(22) = DYNFCOEF
    # AS(23) = VCORE(1)*VSTAR
    # AS(24) = VCORE(2)*VSTAR
    # AS(25) = VCORE(3)*VSTAR
    # AS(26) = RSCALE

    # Populate the groups with data

    massdset  = stargrp.create_dataset('mass',  data =  alist[3]*splitarray[0][:,0],dtype='float32')
    # Re-centre star co-ordinates on cluster centre
    posdset   = stargrp.create_dataset('pos',   data =  (alist[2]*splitarray[1] - np.array(alist[6:9])*alist[2]),dtype='float32')
    veldset   = stargrp.create_dataset('vel',   data =  (alist[5]*splitarray[2] - np.array(alist[23:26])),dtype='float32')
    namedset  = stargrp.create_dataset('id',    data = splitarray[3][:,0],dtype='i')
    if (sev):
        kstardset = stargrp.create_dataset('kstar', data = splitarray[5][:,0],dtype='i') 
        lumdset   = stargrp.create_dataset('lum',   data = splitarray[6][:,0],dtype='float32') 
        teffdset  = stargrp.create_dataset('teff',  data = splitarray[7][:,0],dtype='float32') 

    timedset   = clustergrp.create_dataset('age',  data = alist[0]*alist[4])
    nbindset   = clustergrp.create_dataset('nbin', data = alist[1],dtype='i')
    # Re-centre guide centre on cluster centre
    rgdset     = clustergrp.create_dataset('rg',   data = (np.array(alist[9:12])*1000.0+np.array(alist[6:9])*alist[2])) 
    vgdset     = clustergrp.create_dataset('vg',   data = (np.array(alist[12:15])+np.array(alist[23:26])))
    nrocheset  = clustergrp.create_dataset('nbound',data = alist[21])
    boundrocheset = stargrp.create_dataset('bound', data = splitarray[4][:,0],dtype="i")
    rrocheset  = clustergrp.create_dataset('rhm',data = alist[26]*alist[2])
    rcdset     = clustergrp.create_dataset('rcore',data = alist[2]*alist[15])
    ncdset     = clustergrp.create_dataset('ncore', data = alist[16],dtype='i') 

    print " T = %10.3f [NBODY] %10.3f [MYR];"%(alist[0],alist[0]*alist[4])

    # Units information as attributes 
    massdset.attrs["unit"] = "[Msun]"
    posdset.attrs["unit"]  = "[pc] in cluster centre reference frame"               
    veldset.attrs["unit"]  = "[km/s] in cluster centre reference frame"

    if (sev):
        kstardset.attrs["unit"] = "[stellar type] (Hurley et al 2000)"
        lumdset.attrs["unit"]  = "[log10 Lsun]" 
        teffdset.attrs["unit"] = "[log10 Teff]" 

    timedset.attrs["unit"]  = "[Myr]"
    nbindset.attrs["unit"] = "[number] of regularised binaries"
    rgdset.attrs["unit"] = "[pc] in Galactic reference frame"     
    vgdset.attrs["unit"] = "[km/s] in Galactic reference frame"
    nrocheset.attrs["unit"] = "[number] of stars within the tidal radius of the cluster"
    boundrocheset.attrs["unit"] = "[1 or 0] stars within tidal radius of the cluster"
    rrocheset.attrs["unit"] = "[pc] half mass radius of stars within the tidal radius of the cluster"
    rcdset.attrs["unit"] = "[pc] core radius of the cluster"
    ncdset.attrs["unit"] = "[number] of stars inside the core"

    return()
        
        
def main():
    parser = argparse.ArgumentParser(description='Converts OUT3 data from NBODY6 to HDF5 format')
    parser.add_argument('-f',dest='files',action="store",default='OUT3',help='NBODY6 files to convert [default="OUT3"]')
    parser.add_argument('-s', dest='sev',action="store_true", default=False,help='activate reading stellar evolution data [default=False]')

    args = parser.parse_args()

    # open up the hdf5 file!
    f5 = h5py.File('out.hdf5','w')

    # Loop over all NBODY6 OUT3 files
    for file in args.files.split():
        print " File = ",file
        read_nbody6(f5, file, args.sev)

    f5.close()
        
if __name__ == '__main__':
    main()        
